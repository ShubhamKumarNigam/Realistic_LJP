# Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models
This study investigates legal judgment prediction in a realistic scenario within the context of Indian legal judgments, utilizing a range of transformer-based models, including InlegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and GPT-3.5 Turbo. For transformer models, we experiment with hierarchical transformers and the summarization of judgment facts to optimize input for these models. Our experiments with LLMs reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust performance in judgment prediction. Furthermore, incorporating additional legal information, such as statutes and precedents, significantly improves the outcomes of the prediction task. The LLMs also provide explanations for their predictions. To evaluate the quality of these predictions and explanations, we introduce two human evaluation metrics: **Clarity** and **Linking**. Our findings from both automatic and human evaluations indicate that, despite advancements in LLMs, they have yet to achieve magistrate-level performance in judgment prediction and explanation tasks.

Several summarization methods have been used from the link-https://github.com/Law-AI/summarization

